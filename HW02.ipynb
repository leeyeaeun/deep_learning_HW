{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l12Fft2o15eq"
   },
   "source": [
    "# HW02\n",
    "Deep Learning, AI5302, 2025, Spring, (Tue/Thurs 2:30~3:45)\n",
    "***\n",
    "\n",
    "### Problem1. Fully Connected Layer vs Convolution Neural Network\n",
    "- Build your custom CNN model\n",
    "- Check the result CNN has better result than FCN\n",
    "- The test accuracy must bigger than 60%\n",
    "\n",
    "----\n",
    "\n",
    "### Problem2. Train Dogs and Cats data via CNN\n",
    "- Understand the process of training the CNN model with custom dataloader.   \n",
    "(Download URL: https://www.kaggle.com/c/dogs-vs-cats)\n",
    "- Check the result\n",
    "- The test accuracy must bigger than 60%\n",
    "\n",
    "***\n",
    "### You can add additional code for checking your image and model.\n",
    "### You must summit ``.ipynb`` file. Do not summit ``.py`` file.\n",
    "---\n",
    "\n",
    "### How to submit your homework\n",
    "Submit your jupyter notebook file with the filename of  *HW02_studentnumber.ipynb*  on GEL\n",
    "\n",
    "Ex) HW02_20222015.ipynb  \n",
    "\n",
    "### Submission deadline\n",
    "2025.05.08, Sunday 23:59 (PM)\n",
    "\n",
    "### Plagiarism\n",
    "We encourage you to discuss this homework with your friends or TA, but you should write your own code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD1clLaR-8Dm"
   },
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gczKrj5F4-0Z"
   },
   "source": [
    "## Problem 1. (total 10 pt.)\n",
    "- **Fully Connected Layer vs Convolution Neural Network**\n",
    "- We will use cifar10 dataset.\n",
    "- You have to compare with HW1 result and check CNN model has better result.\n",
    "- The test accuracy of CNN model must bigger than 60%.   \n",
    "- Reference : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsP6ek_hQLrf"
   },
   "source": [
    "### Problem 1-1. (2 pt.)\n",
    "- **Step 1**. Import package.  \n",
    "- **Step 2**. Define device and configure hyperparameters.  \n",
    "- **Step 3**. Download then load Cifar10 dataset to dataloader. You have to adjust transform.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O4odsWMnuDrq"
   },
   "outputs": [],
   "source": [
    "''' Step 1 '''\n",
    "import torch\n",
    "# import ...\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "c7yy42AoQLrg"
   },
   "outputs": [],
   "source": [
    "''' Step 2 '''\n",
    "GPU_NUM = 0\n",
    "lr = 1e-3\n",
    "num_classes = 10\n",
    "batch_size = 512\n",
    "num_epochs = 100\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rrRnBvucQLrg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "''' Step 3 '''\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# transforms.RandomCrop(32, padding=4),      \n",
    "#                                 transforms.RandomHorizontalFlip(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6GJ_6hHQLrh"
   },
   "source": [
    "### Problem 1-2. (5 pt.)\n",
    "- **Step 1**. Build your CNN model.  \n",
    "- **Step 2**. Configure optimizer and objective function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ecyne8NzQLrh"
   },
   "outputs": [],
   "source": [
    "''' Step 1 '''\n",
    "# you have to change class name!\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, padding=2)\n",
    "        self.bn1   = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ozCGI0GqQLri"
   },
   "outputs": [],
   "source": [
    "''' Step 2 '''\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "model = net.to(device)\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qArYp1_kQLri"
   },
   "source": [
    "### Problem 1-3. (3 pt.)\n",
    "- **Step 1**. The method for model training\n",
    "- **Step 2**. The method for testing model\n",
    "- **Step 3**. Train the model and check the test results\n",
    "- **Step 4**. Check the output after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h0ipIhAjQLri"
   },
   "outputs": [],
   "source": [
    "''' Step 1 '''\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def train(model, trainloader, optimizer): \n",
    "    # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TxcXC-7dQLri"
   },
   "outputs": [],
   "source": [
    "''' Step 2 '''\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in testloader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(image).to(device)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= (len(testloader.dataset) / batch_size)\n",
    "    test_accuracy = 100. * correct / len(testloader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qw1jc_6CQLrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "\n",
      "[EPOCH: 1/100], \tTest Loss: 2.3304, \tTest Accuracy: 12.71 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 2/100], \tTest Loss: 2.2580, \tTest Accuracy: 18.31 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 3/100], \tTest Loss: 2.1110, \tTest Accuracy: 25.94 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 4/100], \tTest Loss: 1.9434, \tTest Accuracy: 31.51 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 5/100], \tTest Loss: 1.8300, \tTest Accuracy: 35.03 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 6/100], \tTest Loss: 1.7485, \tTest Accuracy: 38.07 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 7/100], \tTest Loss: 1.6842, \tTest Accuracy: 40.40 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 8/100], \tTest Loss: 1.6304, \tTest Accuracy: 41.88 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 9/100], \tTest Loss: 1.5884, \tTest Accuracy: 43.65 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 10/100], \tTest Loss: 1.5412, \tTest Accuracy: 45.32 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 11/100], \tTest Loss: 1.5176, \tTest Accuracy: 46.07 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 12/100], \tTest Loss: 1.4758, \tTest Accuracy: 47.57 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 13/100], \tTest Loss: 1.4645, \tTest Accuracy: 47.64 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 14/100], \tTest Loss: 1.4312, \tTest Accuracy: 49.42 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 15/100], \tTest Loss: 1.3906, \tTest Accuracy: 50.62 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 16/100], \tTest Loss: 1.3806, \tTest Accuracy: 51.67 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 17/100], \tTest Loss: 1.3489, \tTest Accuracy: 52.70 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 18/100], \tTest Loss: 1.3344, \tTest Accuracy: 53.07 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 19/100], \tTest Loss: 1.3166, \tTest Accuracy: 54.20 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 20/100], \tTest Loss: 1.2982, \tTest Accuracy: 54.95 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 21/100], \tTest Loss: 1.3354, \tTest Accuracy: 54.00 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 22/100], \tTest Loss: 1.2755, \tTest Accuracy: 55.62 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 23/100], \tTest Loss: 1.2588, \tTest Accuracy: 56.19 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 24/100], \tTest Loss: 1.2509, \tTest Accuracy: 56.76 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 25/100], \tTest Loss: 1.2912, \tTest Accuracy: 55.45 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 26/100], \tTest Loss: 1.2173, \tTest Accuracy: 57.78 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 27/100], \tTest Loss: 1.2039, \tTest Accuracy: 58.37 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 28/100], \tTest Loss: 1.2658, \tTest Accuracy: 56.25 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 29/100], \tTest Loss: 1.1874, \tTest Accuracy: 58.70 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 30/100], \tTest Loss: 1.1744, \tTest Accuracy: 59.64 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 31/100], \tTest Loss: 1.2169, \tTest Accuracy: 57.93 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 32/100], \tTest Loss: 1.1648, \tTest Accuracy: 59.75 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 33/100], \tTest Loss: 1.1854, \tTest Accuracy: 58.95 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 34/100], \tTest Loss: 1.1427, \tTest Accuracy: 60.82 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 35/100], \tTest Loss: 1.1534, \tTest Accuracy: 60.05 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 36/100], \tTest Loss: 1.1327, \tTest Accuracy: 61.02 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 37/100], \tTest Loss: 1.1362, \tTest Accuracy: 60.90 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 38/100], \tTest Loss: 1.1242, \tTest Accuracy: 60.95 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 39/100], \tTest Loss: 1.1218, \tTest Accuracy: 61.37 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 40/100], \tTest Loss: 1.1125, \tTest Accuracy: 61.48 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 41/100], \tTest Loss: 1.1240, \tTest Accuracy: 61.07 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 42/100], \tTest Loss: 1.1165, \tTest Accuracy: 61.57 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 43/100], \tTest Loss: 1.1084, \tTest Accuracy: 61.78 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 44/100], \tTest Loss: 1.0926, \tTest Accuracy: 62.41 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 45/100], \tTest Loss: 1.0819, \tTest Accuracy: 62.97 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 46/100], \tTest Loss: 1.0813, \tTest Accuracy: 62.95 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 47/100], \tTest Loss: 1.1022, \tTest Accuracy: 62.50 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 48/100], \tTest Loss: 1.1011, \tTest Accuracy: 62.24 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 49/100], \tTest Loss: 1.0755, \tTest Accuracy: 62.79 % lr=1.0e-03, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 50/100], \tTest Loss: 1.0664, \tTest Accuracy: 63.46 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 51/100], \tTest Loss: 1.0636, \tTest Accuracy: 63.37 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 52/100], \tTest Loss: 1.0670, \tTest Accuracy: 63.41 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 53/100], \tTest Loss: 1.0663, \tTest Accuracy: 63.04 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 54/100], \tTest Loss: 1.0678, \tTest Accuracy: 63.28 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 55/100], \tTest Loss: 1.0585, \tTest Accuracy: 63.55 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 56/100], \tTest Loss: 1.0654, \tTest Accuracy: 63.49 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 57/100], \tTest Loss: 1.0617, \tTest Accuracy: 63.21 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 58/100], \tTest Loss: 1.0504, \tTest Accuracy: 63.78 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 59/100], \tTest Loss: 1.0547, \tTest Accuracy: 64.09 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 60/100], \tTest Loss: 1.0552, \tTest Accuracy: 63.71 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 61/100], \tTest Loss: 1.0499, \tTest Accuracy: 63.78 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 62/100], \tTest Loss: 1.0554, \tTest Accuracy: 63.65 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 63/100], \tTest Loss: 1.0466, \tTest Accuracy: 64.04 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 64/100], \tTest Loss: 1.0512, \tTest Accuracy: 63.77 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 65/100], \tTest Loss: 1.0468, \tTest Accuracy: 64.21 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 66/100], \tTest Loss: 1.0572, \tTest Accuracy: 64.05 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 67/100], \tTest Loss: 1.0490, \tTest Accuracy: 64.19 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 68/100], \tTest Loss: 1.0449, \tTest Accuracy: 64.01 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 69/100], \tTest Loss: 1.0438, \tTest Accuracy: 64.11 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 70/100], \tTest Loss: 1.0373, \tTest Accuracy: 64.31 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 71/100], \tTest Loss: 1.0341, \tTest Accuracy: 64.42 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 72/100], \tTest Loss: 1.0376, \tTest Accuracy: 64.36 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 73/100], \tTest Loss: 1.0396, \tTest Accuracy: 64.14 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 74/100], \tTest Loss: 1.0388, \tTest Accuracy: 64.38 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 75/100], \tTest Loss: 1.0352, \tTest Accuracy: 64.34 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 76/100], \tTest Loss: 1.0303, \tTest Accuracy: 64.59 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 77/100], \tTest Loss: 1.0283, \tTest Accuracy: 64.75 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 78/100], \tTest Loss: 1.0313, \tTest Accuracy: 64.55 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 79/100], \tTest Loss: 1.0333, \tTest Accuracy: 64.45 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 80/100], \tTest Loss: 1.0481, \tTest Accuracy: 64.03 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 81/100], \tTest Loss: 1.0392, \tTest Accuracy: 64.50 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 82/100], \tTest Loss: 1.0346, \tTest Accuracy: 64.24 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 83/100], \tTest Loss: 1.0273, \tTest Accuracy: 64.83 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 84/100], \tTest Loss: 1.0270, \tTest Accuracy: 64.82 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 85/100], \tTest Loss: 1.0262, \tTest Accuracy: 64.69 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 86/100], \tTest Loss: 1.0201, \tTest Accuracy: 65.01 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 87/100], \tTest Loss: 1.0192, \tTest Accuracy: 64.98 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 88/100], \tTest Loss: 1.0257, \tTest Accuracy: 64.48 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 89/100], \tTest Loss: 1.0236, \tTest Accuracy: 64.83 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 90/100], \tTest Loss: 1.0329, \tTest Accuracy: 64.90 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 91/100], \tTest Loss: 1.0318, \tTest Accuracy: 64.19 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 92/100], \tTest Loss: 1.0367, \tTest Accuracy: 64.11 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 93/100], \tTest Loss: 1.0160, \tTest Accuracy: 65.24 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 94/100], \tTest Loss: 1.0179, \tTest Accuracy: 65.45 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 95/100], \tTest Loss: 1.0154, \tTest Accuracy: 65.16 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 96/100], \tTest Loss: 1.0243, \tTest Accuracy: 64.54 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 97/100], \tTest Loss: 1.0149, \tTest Accuracy: 64.89 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 98/100], \tTest Loss: 1.0282, \tTest Accuracy: 64.96 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 99/100], \tTest Loss: 1.0155, \tTest Accuracy: 64.84 % lr=5.0e-04, \n",
      "\n",
      "Finished Training\n",
      "\n",
      "[EPOCH: 100/100], \tTest Loss: 1.0341, \tTest Accuracy: 64.43 % lr=2.5e-04, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Step 3 '''    \n",
    "net = CNN().to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(net, trainloader, optimizer)\n",
    "    test_loss, test_accuracy = test(net, testloader)\n",
    "    scheduler.step()\n",
    "    print(f\"\\n[EPOCH: {epoch}/{num_epochs}], \\tTest Loss: { test_loss:.4f}, \\tTest Accuracy: {test_accuracy:.2f} % lr={scheduler.get_last_lr()[0]:.1e}, \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "VulDjbUpQLrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 68.4 %\n",
      "Accuracy for class: car   is 80.5 %\n",
      "Accuracy for class: bird  is 58.8 %\n",
      "Accuracy for class: cat   is 42.9 %\n",
      "Accuracy for class: deer  is 52.3 %\n",
      "Accuracy for class: dog   is 54.0 %\n",
      "Accuracy for class: frog  is 71.4 %\n",
      "Accuracy for class: horse is 64.6 %\n",
      "Accuracy for class: ship  is 73.7 %\n",
      "Accuracy for class: truck is 78.0 %\n"
     ]
    }
   ],
   "source": [
    "''' Step 4 '''\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVshAnR7QLrj"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzXL1yhCQLrj"
   },
   "source": [
    "## Problem 2. (Total 10 pt.)\n",
    "- **Train Dogs and Cats data via CNN**\n",
    "- **You must set the class that Dogs are 0 and Cats are 1.**\n",
    "- Understand the process of training the CNN model with custom dataloader.\n",
    "- Download the dataset from below.   \n",
    "https://www.kaggle.com/c/dogs-vs-cats\n",
    "- The test accuracy of CNN model must bigger than 60%.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2FIGQRP5AMc"
   },
   "source": [
    "### Problem 2-1. (4 pt.)\n",
    "- **Step 1**. Import package.  \n",
    "- **Step 2**. Define device and configure hyperparameters.  \n",
    "- **Step 3**. Load **Dogs and Cats** dataset to dataloader. You have to adjust transform.  \n",
    "**You can label dataset via images name at train folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-V47SD_74_X2"
   },
   "outputs": [],
   "source": [
    "''' Step 1 '''\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "yDllJkdAQLrk"
   },
   "outputs": [],
   "source": [
    "''' Step 2 '''\n",
    "GPU_NUM = 0\n",
    "lr = 1e-4\n",
    "num_classes = 10\n",
    "batch_size = 512\n",
    "num_epochs = 250\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "gi8X2HxjQLrk"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "''' Step 3 '''\n",
    "IMG_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "class DogCatData(Dataset):\n",
    "    def __init__(self, img_dir, IMG_SIZE = 32, transform = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.file_names = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, file_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # 1 = dog, 0 = cat\n",
    "        label = 0 if file_name.startswith(\"cat\") else 1\n",
    "\n",
    "        transformed_img = self.transform(img)\n",
    "\n",
    "        return transformed_img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "working_dir = \"/root/deeplearningHW/dogs-vs-cats/train\"\n",
    "\n",
    "train_data = DogCatData(working_dir, IMG_SIZE, transform)\n",
    "train_loader = DataLoader(train_data, shuffle = True, batch_size = 4)\n",
    "\n",
    "val_dir = \"/root/deeplearningHW/dogs-vs-cats/test1\"\n",
    "val_data = DogCatData(val_dir, IMG_SIZE, transform)\n",
    "val_loader = DataLoader(val_data, shuffle = True, batch_size = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    }
   ],
   "source": [
    "print('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwU3wjwQQLrk"
   },
   "source": [
    "### Problem 2-2. (3 pt.)\n",
    "- **Step 1**. Build your CNN model.  \n",
    "(It doesn't matter if you use same model at problem 1.)\n",
    "- **Step 2**. Configure optimizer and objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "1_gWx7gqQLrl"
   },
   "outputs": [],
   "source": [
    "''' Step 1 '''\n",
    "\n",
    "class CNN_dogs_cats(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, padding=2)\n",
    "        self.bn1   = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 30 * 30, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "dcnet = CNN_dogs_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "RvJ3tu-qQLrl"
   },
   "outputs": [],
   "source": [
    "''' Step 2 '''\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = torch.optim.AdamW(dcnet.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEXKlY8IQLrl"
   },
   "source": [
    "### Problem 2-3. (3 pt.)\n",
    "- **Step 1**. The method for model training\n",
    "- **Step 2**. The method for validation model\n",
    "- **Step 3**. Train the model and check the validation results\n",
    "- **Step 4**. Check the test result by **ten** samples with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "xj7XgSNxQLrl"
   },
   "outputs": [],
   "source": [
    "''' Step 1 '''\n",
    "def traindc(model, train_loader, optimizer, criterion): \n",
    "    # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print('Finished Training')\n",
    "    return epoch_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "q5JXNtXXQLrl"
   },
   "outputs": [],
   "source": [
    "''' Step 2 '''\n",
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc  = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "H3tgJ16sQLrl"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m''' Step 3 '''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m dcnet\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "''' Step 3 '''\n",
    "num_epochs = 20\n",
    "torch.cuda.empty_cache()\n",
    "model = dcnet.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = traindc(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "    print(f\"[Epoch {epoch}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f}  \"\n",
    "          f\"Val Loss: {val_loss:.4f}  \"\n",
    "          f\"Val Acc: {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRmeJxTgQLrl"
   },
   "outputs": [],
   "source": [
    "''' Step 4 '''\n",
    "\n",
    "inv_norm = transforms.Normalize(\n",
    "    mean=[-m/s for m, s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
    "    std=[1/s for s in [0.229,0.224,0.225]]\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        for i in range(inputs.size(0)):\n",
    "            if count >= 10: break\n",
    "            ax = fig.add_subplot(2, 5, count+1)\n",
    "            img = inv_norm(inputs[i]).cpu().permute(1,2,0).numpy()\n",
    "            ax.imshow(np.clip(img, 0, 1))\n",
    "            ax.set_title(f\"P:{preds[i].item()} / T:{labels[i].item()}\")\n",
    "            ax.axis('off')\n",
    "            count += 1\n",
    "        if count >= 10: break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
